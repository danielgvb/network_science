{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584c98b2-aac8-4390-afe9-f993b853fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from huggingface_hub import hf_hub_download\n",
    "from ultralytics import YOLO\n",
    "from supervision import Detections\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a993be-3826-4329-8f50-0877f181afff",
   "metadata": {},
   "source": [
    "# Smple usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007cb21-ee9e-46d9-a5bc-ead46fe0c992",
   "metadata": {},
   "source": [
    "source = https://huggingface.co/arnabdhar/YOLOv8-Face-Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58115f17-49c9-4eb2-9cf3-8ad2dbd4d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x512 (no detections), 133.6ms\n",
      "Speed: 0.0ms preprocess, 133.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n"
     ]
    }
   ],
   "source": [
    "# download model\n",
    "model_path = hf_hub_download(repo_id=\"arnabdhar/YOLOv8-Face-Detection\", filename=\"model.pt\")\n",
    "\n",
    "# load model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# inference\n",
    "image_path = \"sample/2022-11-30_16-58-45_UTC_6.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Perform inference\n",
    "output = model(image\n",
    "              \n",
    "results = Detections.from_ultralytics(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc0235d8-cca5-429c-b0a9-09492fe9e527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "masks: None\n",
       "names: {0: 'FACE'}\n",
       "obb: None\n",
       "orig_img: array([[[220, 210, 200],\n",
       "        [220, 210, 200],\n",
       "        [221, 211, 201],\n",
       "        ...,\n",
       "        [210, 187, 171],\n",
       "        [212, 189, 173],\n",
       "        [214, 191, 175]],\n",
       "\n",
       "       [[220, 210, 200],\n",
       "        [220, 210, 200],\n",
       "        [221, 211, 201],\n",
       "        ...,\n",
       "        [210, 187, 171],\n",
       "        [212, 189, 173],\n",
       "        [214, 191, 175]],\n",
       "\n",
       "       [[220, 210, 200],\n",
       "        [220, 210, 200],\n",
       "        [221, 211, 201],\n",
       "        ...,\n",
       "        [210, 187, 171],\n",
       "        [212, 189, 173],\n",
       "        [214, 191, 175]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 52,  42,  32],\n",
       "        [ 64,  55,  42],\n",
       "        [ 78,  66,  54],\n",
       "        ...,\n",
       "        [ 45,  36,  23],\n",
       "        [ 46,  37,  23],\n",
       "        [ 48,  39,  25]],\n",
       "\n",
       "       [[ 42,  32,  22],\n",
       "        [ 47,  38,  25],\n",
       "        [ 50,  38,  26],\n",
       "        ...,\n",
       "        [ 44,  35,  22],\n",
       "        [ 45,  36,  22],\n",
       "        [ 47,  38,  24]],\n",
       "\n",
       "       [[ 34,  24,  14],\n",
       "        [ 34,  25,  12],\n",
       "        [ 32,  20,   8],\n",
       "        ...,\n",
       "        [ 44,  35,  22],\n",
       "        [ 45,  36,  22],\n",
       "        [ 45,  36,  22]]], dtype=uint8)\n",
       "orig_shape: (1349, 1080)\n",
       "path: 'sample/2022-11-30_16-58-45_UTC_6.jpg'\n",
       "probs: None\n",
       "save_dir: None\n",
       "speed: {'preprocess': 0.0, 'inference': 133.5916519165039, 'postprocess': 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ccd0ff5-9971-4a25-ab71-882fb06a44c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([])\n",
       "conf: tensor([])\n",
       "data: tensor([], size=(0, 6))\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (1349, 1080)\n",
       "shape: torch.Size([0, 6])\n",
       "xywh: tensor([], size=(0, 4))\n",
       "xywhn: tensor([], size=(0, 4))\n",
       "xyxy: tensor([], size=(0, 4))\n",
       "xyxyn: tensor([], size=(0, 4))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84115f1a-bf4a-480e-b9e6-c6f38b0e8eb5",
   "metadata": {},
   "source": [
    "# Label all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0c51fe-b808-443f-a166-91f5461c0fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../1_download_data/data/raw/-PHbiexlr_\\\\2015-11-18_18-26-59_UTC.jpg',\n",
       " '../1_download_data/data/raw/3YO1o0Rlkt\\\\2015-06-01_07-45-08_UTC.jpg',\n",
       " '../1_download_data/data/raw/4yqgDyxloK\\\\2015-07-06_10-38-30_UTC.jpg',\n",
       " '../1_download_data/data/raw/B-y2Fo8qcN_\\\\2020-04-10_08-57-20_UTC.jpg',\n",
       " '../1_download_data/data/raw/B3__d73i46x\\\\2019-10-24_11-49-40_UTC.jpg',\n",
       " '../1_download_data/data/raw/B8zBgZeD8bQ\\\\2020-02-20_17-34-19_UTC.jpg',\n",
       " '../1_download_data/data/raw/B9UltWvIDjA\\\\2020-03-04_18-25-36_UTC.jpg',\n",
       " '../1_download_data/data/raw/B9XY-IjjDWt\\\\2020-03-05_20-32-01_UTC_1.jpg',\n",
       " '../1_download_data/data/raw/B9XY-IjjDWt\\\\2020-03-05_20-32-01_UTC_2.jpg',\n",
       " '../1_download_data/data/raw/BBIHpekRlhD\\\\2016-01-29_14-48-24_UTC.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Replace this with the directory you want to search in\n",
    "directory = '../1_download_data/data/raw/'\n",
    "\n",
    "\n",
    "def get_jpg_files(folder_path):\n",
    "    jpg_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                jpg_files.append(os.path.join(root, file))\n",
    "    return jpg_files\n",
    "\n",
    "# Example usage\n",
    "folder_path = '../1_download_data/data/raw/'\n",
    "jpg_files = get_jpg_files(folder_path)\n",
    "jpg_files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af4e36-f0ff-46d3-add1-0118de067e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "from tqdm import tqdm\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  # Allow loading of truncated images\n",
    "dict_face_detection = {}\n",
    "for image in tqdm(jpg_files):\n",
    "    short_name = image.split('\\\\')[1]\n",
    "    try:\n",
    "        with Image.open(image) as img:\n",
    "            raw_image = img.convert('RGB')\n",
    "            # Further processing of raw_image if needed\n",
    "            # unconditional image captioning\n",
    "            text = \"a picture of \"\n",
    "            inputs = processor(raw_image, text, return_tensors=\"pt\").to(device)\n",
    "            out = model.generate(**inputs, num_beams = 3)\n",
    "            dict_captions[short_name] = processor.decode(out[0], skip_special_tokens=True)\n",
    "    except IOError as e:\n",
    "        print(f\"Cannot process image {image}: {e}\")\n",
    "        dict_captions[short_name] = ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
