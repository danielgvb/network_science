{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584c98b2-aac8-4390-afe9-f993b853fc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\ds_master\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "from huggingface_hub import hf_hub_download\n",
    "from ultralytics import YOLO\n",
    "from supervision import Detections\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a993be-3826-4329-8f50-0877f181afff",
   "metadata": {},
   "source": [
    "# Sample usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007cb21-ee9e-46d9-a5bc-ead46fe0c992",
   "metadata": {},
   "source": [
    "source = https://huggingface.co/arnabdhar/YOLOv8-Face-Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "58115f17-49c9-4eb2-9cf3-8ad2dbd4d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x512 (no detections), 123.6ms\n",
      "Speed: 3.2ms preprocess, 123.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n"
     ]
    }
   ],
   "source": [
    "# download model\n",
    "model_path = hf_hub_download(repo_id=\"arnabdhar/YOLOv8-Face-Detection\", filename=\"model.pt\")\n",
    "\n",
    "# load model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# inference\n",
    "#image_path = \"sample/2013-10-08_12-40-36_UTC.jpg\" # face\n",
    "image_path = \"sample/2022-11-30_16-58-45_UTC_6.jpg\" # no face\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Perform inference\n",
    "output = model(image, save_conf=True)\n",
    "results = Detections.from_ultralytics(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e56c192-1ae8-4faf-9a72-f6cedb1ff1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 FACE, 145.1ms\n",
      "Speed: 0.8ms preprocess, 145.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# see face detection\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#model = YOLO('yolov8n.pt')\n",
    "results = model(image, save_conf=True)  # results list\n",
    "for r in results:\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    im.show()  # show image\n",
    "    im.save('results.jpg')  # save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d02ad192-e7fa-418b-b6ba-4ba071252081",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "35f6452e-f8f7-4c40-8565-8ba37dc59897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output[0].boxes.xyxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fbbe631d-220f-4286-91a7-03ed40af3ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor is empty. No element to access.\n"
     ]
    }
   ],
   "source": [
    "# Example tensor\n",
    "tensor = output[0].boxes.xyxy  # Replace with your tensor\n",
    "\n",
    "# Accessing the first element\n",
    "if tensor.numel() > 0:  # Check if the tensor is not empty\n",
    "    first_element = tensor[0]\n",
    "    print(\"First element:\", first_element)\n",
    "else:\n",
    "    print(\"The tensor is empty. No element to access.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4db1a7e-4bcc-4f4d-b0d4-f95550b7f44b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mxyxy[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "output[0].boxes.xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cfc495c2-9b6e-4170-be9e-5e9ffd256286",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84115f1a-bf4a-480e-b9e6-c6f38b0e8eb5",
   "metadata": {},
   "source": [
    "# Label all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "af0c51fe-b808-443f-a166-91f5461c0fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../1_download_data/data/raw/-PHbiexlr_\\\\2015-11-18_18-26-59_UTC.jpg',\n",
       " '../1_download_data/data/raw/3YO1o0Rlkt\\\\2015-06-01_07-45-08_UTC.jpg',\n",
       " '../1_download_data/data/raw/4yqgDyxloK\\\\2015-07-06_10-38-30_UTC.jpg',\n",
       " '../1_download_data/data/raw/B-y2Fo8qcN_\\\\2020-04-10_08-57-20_UTC.jpg',\n",
       " '../1_download_data/data/raw/B3__d73i46x\\\\2019-10-24_11-49-40_UTC.jpg',\n",
       " '../1_download_data/data/raw/B8zBgZeD8bQ\\\\2020-02-20_17-34-19_UTC.jpg',\n",
       " '../1_download_data/data/raw/B9UltWvIDjA\\\\2020-03-04_18-25-36_UTC.jpg',\n",
       " '../1_download_data/data/raw/B9XY-IjjDWt\\\\2020-03-05_20-32-01_UTC_1.jpg',\n",
       " '../1_download_data/data/raw/B9XY-IjjDWt\\\\2020-03-05_20-32-01_UTC_2.jpg',\n",
       " '../1_download_data/data/raw/BBIHpekRlhD\\\\2016-01-29_14-48-24_UTC.jpg']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Replace this with the directory you want to search in\n",
    "directory = '../1_download_data/data/raw/'\n",
    "\n",
    "\n",
    "def get_jpg_files(folder_path):\n",
    "    jpg_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                jpg_files.append(os.path.join(root, file))\n",
    "    return jpg_files\n",
    "\n",
    "# Example usage\n",
    "folder_path = '../1_download_data/data/raw/'\n",
    "jpg_files = get_jpg_files(folder_path)\n",
    "jpg_files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e500a-e053-4534-ad96-59a2caae2e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)\n",
    "\n",
    "# Perform inference\n",
    "output = model(image, save_conf=True)\n",
    "results = Detections.from_ultralytics(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df0976c-6fe4-44f6-81d4-c2fd119599d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_face_detection[image] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "11af4e36-f0ff-46d3-add1-0118de067e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 FACEs, 124.0ms\n",
      "Speed: 4.9ms preprocess, 124.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:00<00:01,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 FACE, 129.7ms\n",
      "Speed: 3.0ms preprocess, 129.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:00<00:01,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 FACEs, 126.6ms\n",
      "Speed: 12.9ms preprocess, 126.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:00<00:01,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x512 (no detections), 106.0ms\n",
      "Speed: 16.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:00<00:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 FACE, 77.3ms\n",
      "Speed: 2.0ms preprocess, 77.3ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:00<00:00,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x544 1 FACE, 95.2ms\n",
      "Speed: 3.0ms preprocess, 95.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 544)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:01<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x544 2 FACEs, 115.5ms\n",
      "Speed: 17.7ms preprocess, 115.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 544)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:01<00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x512 (no detections), 99.0ms\n",
      "Speed: 14.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:01<00:00,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x512 (no detections), 97.2ms\n",
      "Speed: 3.0ms preprocess, 97.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:01<00:00,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 FACE, 116.8ms\n",
      "Speed: 0.0ms preprocess, 116.8ms inference, 15.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "dict_face_detection = {}\n",
    "for image_path in tqdm(jpg_files[0:10]):\n",
    "    short_name = image_path.split('\\\\')[1]\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        # Perform inference\n",
    "        output = model(image)\n",
    "        results = Detections.from_ultralytics(output[0])\n",
    "        tensor = output[0].boxes.xyxy  # Replace with your tensor\n",
    "        # Accessing the first element\n",
    "        if tensor.numel() > 0:  # Check if the tensor is not empty\n",
    "            dict_face_detection[short_name] = 1\n",
    "        else:\n",
    "            dict_face_detection[short_name] = 0\n",
    "    except:\n",
    "        pass\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ae31f052-b92a-4a27-886d-8bd5fe130bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2015-11-18_18-26-59_UTC.jpg': 1,\n",
       " '2015-06-01_07-45-08_UTC.jpg': 1,\n",
       " '2015-07-06_10-38-30_UTC.jpg': 1,\n",
       " '2020-04-10_08-57-20_UTC.jpg': 0,\n",
       " '2019-10-24_11-49-40_UTC.jpg': 1,\n",
       " '2020-02-20_17-34-19_UTC.jpg': 1,\n",
       " '2020-03-04_18-25-36_UTC.jpg': 1,\n",
       " '2020-03-05_20-32-01_UTC_1.jpg': 0,\n",
       " '2020-03-05_20-32-01_UTC_2.jpg': 0,\n",
       " '2016-01-29_14-48-24_UTC.jpg': 1}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_face_detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
