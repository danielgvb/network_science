{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584c98b2-aac8-4390-afe9-f993b853fc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\ds_master\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "from huggingface_hub import hf_hub_download\n",
    "from ultralytics import YOLO\n",
    "from supervision import Detections\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a993be-3826-4329-8f50-0877f181afff",
   "metadata": {},
   "source": [
    "# Smple usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007cb21-ee9e-46d9-a5bc-ead46fe0c992",
   "metadata": {},
   "source": [
    "source = https://huggingface.co/arnabdhar/YOLOv8-Face-Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58115f17-49c9-4eb2-9cf3-8ad2dbd4d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 FACE, 145.8ms\n",
      "Speed: 4.5ms preprocess, 145.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# download model\n",
    "model_path = hf_hub_download(repo_id=\"arnabdhar/YOLOv8-Face-Detection\", filename=\"model.pt\")\n",
    "\n",
    "# load model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# inference\n",
    "image_path = \"sample/2014-03-21_10-14-52_UTC.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Perform inference\n",
    "output = model(image)\n",
    "              \n",
    "results = Detections.from_ultralytics(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e53262c7-6e37-48f8-824f-72dea5a238cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Detections(xyxy=array([], shape=(0, 4), dtype=float32), mask=None, confidence=array([], dtype=float32), class_id=array([], dtype=int32), tracker_id=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_detections = Detections.empty()\n",
    "empty_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "124adaae-c00b-4882-a72e-1a029e264dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "supervision.detection.core.Detections"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d65d0e4-d9fb-4a93-93a3-89657fcd0a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 FACE, 117.0ms\n",
      "Speed: 8.0ms preprocess, 117.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Detections(xyxy=array([[     131.98,       62.93,       210.4,      171.24]], dtype=float32), mask=None, confidence=array([    0.82755], dtype=float32), class_id=array([0]), tracker_id=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "\n",
    "#model = YOLO('yolov8s.pt')\n",
    "\n",
    "image = cv2.imread(\"sample/2022-11-30_16-58-45_UTC_6.jpg\")\n",
    "\n",
    "result = model(image)[0]\n",
    "detections = sv.Detections.from_ultralytics(result)\n",
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc0235d8-cca5-429c-b0a9-09492fe9e527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 FACE, 126.0ms\n",
      "Speed: 3.0ms preprocess, 126.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "image_path2 = \"sample/2014-03-21_10-14-52_UTC.jpg\"\n",
    "image2 = Image.open(image_path2)\n",
    "\n",
    "# Perform inference\n",
    "output2 = model(image2)\n",
    "              \n",
    "results2 = Detections.from_ultralytics(output2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f1883ca-8cdc-4cc5-a318-d0817d9e8454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "supervision.detection.core.Detections"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d844190e-0e4a-4252-bc78-76c5f488f5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Detections(xyxy=array([[     132.13,      62.979,       210.4,      171.42]], dtype=float32), mask=None, confidence=array([    0.82998], dtype=float32), class_id=array([0]), tracker_id=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84115f1a-bf4a-480e-b9e6-c6f38b0e8eb5",
   "metadata": {},
   "source": [
    "# Label all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0c51fe-b808-443f-a166-91f5461c0fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../1_download_data/data/raw/-PHbiexlr_\\\\2015-11-18_18-26-59_UTC.jpg',\n",
       " '../1_download_data/data/raw/3YO1o0Rlkt\\\\2015-06-01_07-45-08_UTC.jpg',\n",
       " '../1_download_data/data/raw/4yqgDyxloK\\\\2015-07-06_10-38-30_UTC.jpg',\n",
       " '../1_download_data/data/raw/B-y2Fo8qcN_\\\\2020-04-10_08-57-20_UTC.jpg',\n",
       " '../1_download_data/data/raw/B3__d73i46x\\\\2019-10-24_11-49-40_UTC.jpg',\n",
       " '../1_download_data/data/raw/B8zBgZeD8bQ\\\\2020-02-20_17-34-19_UTC.jpg',\n",
       " '../1_download_data/data/raw/B9UltWvIDjA\\\\2020-03-04_18-25-36_UTC.jpg',\n",
       " '../1_download_data/data/raw/B9XY-IjjDWt\\\\2020-03-05_20-32-01_UTC_1.jpg',\n",
       " '../1_download_data/data/raw/B9XY-IjjDWt\\\\2020-03-05_20-32-01_UTC_2.jpg',\n",
       " '../1_download_data/data/raw/BBIHpekRlhD\\\\2016-01-29_14-48-24_UTC.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Replace this with the directory you want to search in\n",
    "directory = '../1_download_data/data/raw/'\n",
    "\n",
    "\n",
    "def get_jpg_files(folder_path):\n",
    "    jpg_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                jpg_files.append(os.path.join(root, file))\n",
    "    return jpg_files\n",
    "\n",
    "# Example usage\n",
    "folder_path = '../1_download_data/data/raw/'\n",
    "jpg_files = get_jpg_files(folder_path)\n",
    "jpg_files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af4e36-f0ff-46d3-add1-0118de067e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "from tqdm import tqdm\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  # Allow loading of truncated images\n",
    "dict_face_detection = {}\n",
    "for image in tqdm(jpg_files):\n",
    "    short_name = image.split('\\\\')[1]\n",
    "    try:\n",
    "        with Image.open(image) as img:\n",
    "            raw_image = img.convert('RGB')\n",
    "            # Further processing of raw_image if needed\n",
    "            # unconditional image captioning\n",
    "            text = \"a picture of \"\n",
    "            inputs = processor(raw_image, text, return_tensors=\"pt\").to(device)\n",
    "            out = model.generate(**inputs, num_beams = 3)\n",
    "            dict_captions[short_name] = processor.decode(out[0], skip_special_tokens=True)\n",
    "    except IOError as e:\n",
    "        print(f\"Cannot process image {image}: {e}\")\n",
    "        dict_captions[short_name] = ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
