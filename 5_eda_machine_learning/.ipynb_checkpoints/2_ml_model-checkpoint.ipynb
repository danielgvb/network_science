{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083ad3ac-2519-40bc-a934-8f8117f7e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1eac7cd-b155-486c-ac92-20dc34eca967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>face</th>\n",
       "      <th>skin</th>\n",
       "      <th>text_deep_clean</th>\n",
       "      <th>objectifies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../1_download_data/jacquemus\\2022-05-30_15-43-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332761</td>\n",
       "      <td>jacquemus sydney hawai i night tom woman long ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../1_download_data/jacquemus\\2020-11-12_17-00-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138254</td>\n",
       "      <td>jacquemus l annee fw shoot rosa picture woman ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../1_download_data/hm\\2023-09-24_18-34-48_UTC\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>handbag hold close woman wear black dress blac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../1_download_data/jacquemus\\2022-03-23_16-47-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125818</td>\n",
       "      <td>jacquemus le sac rond so happy have work iconi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../1_download_data/chanelofficial\\2023-12-08_1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145028</td>\n",
       "      <td>chanelofficial opening chanel metier art show ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  face      skin  \\\n",
       "0  ../1_download_data/jacquemus\\2022-05-30_15-43-...     0  0.332761   \n",
       "1  ../1_download_data/jacquemus\\2020-11-12_17-00-...     1  0.138254   \n",
       "2  ../1_download_data/hm\\2023-09-24_18-34-48_UTC\\...     0  0.002294   \n",
       "3  ../1_download_data/jacquemus\\2022-03-23_16-47-...     0  0.125818   \n",
       "4  ../1_download_data/chanelofficial\\2023-12-08_1...     1  0.145028   \n",
       "\n",
       "                                     text_deep_clean  objectifies  \n",
       "0  jacquemus sydney hawai i night tom woman long ...            1  \n",
       "1  jacquemus l annee fw shoot rosa picture woman ...            0  \n",
       "2  handbag hold close woman wear black dress blac...            1  \n",
       "3  jacquemus le sac rond so happy have work iconi...            1  \n",
       "4  chanelofficial opening chanel metier art show ...            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../0_data/gold/8_data_model.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be1834d3-51bd-44fa-9c4d-19d288f574ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face</th>\n",
       "      <th>skin</th>\n",
       "      <th>objectifies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1587.000000</td>\n",
       "      <td>1587.000000</td>\n",
       "      <td>1587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.908003</td>\n",
       "      <td>0.228274</td>\n",
       "      <td>0.412098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.289113</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.492368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065017</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159732</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336554</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999600</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              face         skin  objectifies\n",
       "count  1587.000000  1587.000000  1587.000000\n",
       "mean      0.908003     0.228274     0.412098\n",
       "std       0.289113     0.213313     0.492368\n",
       "min       0.000000     0.000000     0.000000\n",
       "25%       1.000000     0.065017     0.000000\n",
       "50%       1.000000     0.159732     0.000000\n",
       "75%       1.000000     0.336554     1.000000\n",
       "max       1.000000     0.999600     1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3cd18b-324b-45ff-8a7c-e681c3839042",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['skin', 'face']]\n",
    "y = df['objectifies']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d71b8b-fe10-481f-868f-4fc125d31ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6331236897274634\n",
      "KNN Accuracy: 0.5723270440251572\n",
      "SVM Accuracy: 0.6226415094339622\n",
      "Decision Tree Accuracy: 0.5241090146750524\n",
      "Random Forest Accuracy: 0.5241090146750524\n",
      "Gradient Boosting Accuracy: 0.59958071278826\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "\n",
    "# Decision Tree\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "dtree_pred = dtree.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rforest = RandomForestClassifier()\n",
    "rforest.fit(X_train, y_train)\n",
    "rforest_pred = rforest.predict(X_test)\n",
    "\n",
    "# Gradient Boosting\n",
    "gboost = GradientBoostingClassifier()\n",
    "gboost.fit(X_train, y_train)\n",
    "gboost_pred = gboost.predict(X_test)\n",
    "\n",
    "# Example of evaluating the models using accuracy\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logreg_pred))\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, knn_pred))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dtree_pred))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rforest_pred))\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, gboost_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e62f38-1787-4b2d-b40c-7ffbf0305ce0",
   "metadata": {},
   "source": [
    "## Use Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8592e580-d5f6-44ae-9063-eb06c83a310e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\ds_master\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeabcbe2-950f-4791-b517-21223137e676",
   "metadata": {},
   "source": [
    "Download the Word2Vec Embeddings and save them locally. Not in this folder because github does not support large files in the free trial\n",
    "GoogleNews-vectors-negative300.bin\n",
    "path to download = https://www.kaggle.com/datasets/leadbest/googlenewsvectorsnegative300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5d7274-6757-42f0-92a3-7f7428bedc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('../../../Embeddings/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin', binary=True) # have embeddings in pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6bd8710-0728-4faf-89a8-dd4a8e1b36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg_vector(sentence, model):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        return np.mean(word_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7cb2cbc-c80b-4792-adcd-1bbabc3c3658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence_vector'] = df['text_deep_clean'].apply(lambda x: sentence_to_avg_vector(x, model))\n",
    "# Assuming you want to use these vectors in a machine learning model\n",
    "X_embeddings = np.array(df['sentence_vector'].tolist())  # Feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bc620f0-c4ac-4760-bca3-a09b77ebab2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.28784180e-02,  4.12375703e-02, -8.36736523e-03, ...,\n",
       "         3.70955020e-02,  3.32760893e-01,  0.00000000e+00],\n",
       "       [ 1.17519209e-02, -1.64370332e-02,  9.43523925e-03, ...,\n",
       "         4.52920683e-02,  1.38254458e-01,  1.00000000e+00],\n",
       "       [ 3.10849268e-02,  3.15718213e-03, -4.59345020e-02, ...,\n",
       "        -8.76686769e-04,  2.29355281e-03,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-1.88683402e-02, -4.65901708e-03, -2.67808698e-02, ...,\n",
       "        -2.97105573e-02,  9.99600309e-01,  0.00000000e+00],\n",
       "       [-2.45157885e-03,  7.34268203e-02, -1.33702597e-02, ...,\n",
       "        -1.53767904e-02,  2.97908093e-02,  1.00000000e+00],\n",
       "       [ 3.72042656e-02, -1.88064575e-03, -3.41339111e-02, ...,\n",
       "         6.53152466e-02,  1.18575488e-01,  1.00000000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined = np.concatenate((X_embeddings, X), axis=1)\n",
    "X_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364a6e9f-b543-460c-81f5-a6b2824e05e8",
   "metadata": {},
   "source": [
    "# Classificator with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b5c583e-3d55-43c7-acb7-ace9f70cfc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['skin', 'face']]\n",
    "y = df['objectifies']\n",
    "model = model = KeyedVectors.load_word2vec_format('../../../Embeddings/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin', binary=True) # have embeddings in pc\n",
    "def sentence_to_avg_vector(sentence, model):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "df['sentence_vector'] = df['text_deep_clean'].apply(lambda x: sentence_to_avg_vector(x, model))\n",
    "# Assuming you want to use these vectors in a machine learning model\n",
    "X_embeddings = np.array(df['sentence_vector'].tolist())  # Feature matrix\n",
    "X_combined = np.concatenate((X_embeddings, X), axis=1)\n",
    "X_combined\n",
    "\n",
    "X0 = X_combined\n",
    "Y = df['objectifies']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X0, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01b8c19e-83cf-49f2-ba9c-f8bd0381dbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6771488469601677\n",
      "KNN Accuracy: 0.6813417190775681\n",
      "SVM Accuracy: 0.6813417190775681\n",
      "Decision Tree Accuracy: 0.5953878406708596\n",
      "Random Forest Accuracy: 0.6834381551362684\n",
      "Gradient Boosting Accuracy: 0.6960167714884696\n"
     ]
    }
   ],
   "source": [
    "'''X = df[['skin', 'face']]\n",
    "y = df['objectifies']\n",
    "model  = KeyedVectors.load_word2vec_format('../../../Embeddings/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin', binary=True) # have embeddings in pc\n",
    "def sentence_to_avg_vector(sentence, model):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "df['sentence_vector'] = df['text_deep_clean'].apply(lambda x: sentence_to_avg_vector(x, model))\n",
    "# Assuming you want to use these vectors in a machine learning model\n",
    "X_embeddings = np.array(df['sentence_vector'].tolist())  # Feature matrix\n",
    "X_combined = np.concatenate((X_embeddings, X), axis=1)\n",
    "X_combined\n",
    "\n",
    "X0 = X_combined\n",
    "Y = df['objectifies']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X0, Y, test_size=0.3, random_state=42)'''\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "\n",
    "# Decision Tree\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "dtree_pred = dtree.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rforest = RandomForestClassifier()\n",
    "rforest.fit(X_train, y_train)\n",
    "rforest_pred = rforest.predict(X_test)\n",
    "\n",
    "# Gradient Boosting\n",
    "gboost = GradientBoostingClassifier()\n",
    "gboost.fit(X_train, y_train)\n",
    "gboost_pred = gboost.predict(X_test)\n",
    "\n",
    "# Example of evaluating the models using accuracy\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logreg_pred))\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, knn_pred))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dtree_pred))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rforest_pred))\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, gboost_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce4d04bf-b28f-4be5-8a7d-088647460021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4120982986767486"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85360579-73fd-495f-b4ec-47c67a967f63",
   "metadata": {},
   "source": [
    "See also F1-score to evaluate best model because dataset is unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1440e10b-c65e-4e0c-b467-acc7124b54ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.5304878048780488\n",
      "KNN F1 Score: 0.6041666666666666\n",
      "SVM F1 Score: 0.5096774193548387\n",
      "Decision Tree F1 Score: 0.5089058524173027\n",
      "Random Forest F1 Score: 0.5465465465465466\n",
      "Gradient Boosting F1 Score: 0.5915492957746478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1 scores\n",
    "f1_logreg = f1_score(y_test, logreg_pred)\n",
    "f1_knn = f1_score(y_test, knn_pred)\n",
    "f1_svm = f1_score(y_test, svm_pred)\n",
    "f1_dtree = f1_score(y_test, dtree_pred)\n",
    "f1_rforest = f1_score(y_test, rforest_pred)\n",
    "f1_gboost = f1_score(y_test, gboost_pred)\n",
    "\n",
    "# Print F1 scores\n",
    "print(\"Logistic Regression F1 Score:\", f1_logreg)\n",
    "print(\"KNN F1 Score:\", f1_knn)\n",
    "print(\"SVM F1 Score:\", f1_svm)\n",
    "print(\"Decision Tree F1 Score:\", f1_dtree)\n",
    "print(\"Random Forest F1 Score:\", f1_rforest)\n",
    "print(\"Gradient Boosting F1 Score:\", f1_gboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba1f36-5761-42e8-9db5-941c0666ec28",
   "metadata": {},
   "source": [
    "Having the best model we can automatically label all the other data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d6a7a-eba9-44cc-9ab8-7d92f7f3a78d",
   "metadata": {},
   "source": [
    "# See feature importance on objectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3d3ad8b-9491-4c7a-906d-1bd38757ffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7064989517819706\n",
      "Feature: word_embedding_191, Importance: 0.018182197585701942\n",
      "Feature: word_embedding_82, Importance: 0.018125800415873528\n",
      "Feature: word_embedding_60, Importance: 0.014764705672860146\n",
      "Feature: word_embedding_66, Importance: 0.013874349184334278\n",
      "Feature: word_embedding_287, Importance: 0.01170937530696392\n",
      "Feature: word_embedding_99, Importance: 0.011149009689688683\n",
      "Feature: word_embedding_226, Importance: 0.011026379652321339\n",
      "Feature: word_embedding_176, Importance: 0.010935235768556595\n",
      "Feature: face, Importance: 0.010844764299690723\n",
      "Feature: word_embedding_291, Importance: 0.010560356080532074\n",
      "Feature: word_embedding_198, Importance: 0.01051478274166584\n",
      "Feature: word_embedding_52, Importance: 0.010360250249505043\n",
      "Feature: word_embedding_216, Importance: 0.01027311198413372\n",
      "Feature: word_embedding_124, Importance: 0.010083691217005253\n",
      "Feature: word_embedding_196, Importance: 0.009522038511931896\n",
      "Feature: word_embedding_48, Importance: 0.009486688300967216\n",
      "Feature: word_embedding_261, Importance: 0.009438087232410908\n",
      "Feature: word_embedding_204, Importance: 0.00896571483463049\n",
      "Feature: word_embedding_251, Importance: 0.008824341930449009\n",
      "Feature: word_embedding_174, Importance: 0.008460937067866325\n",
      "Feature: word_embedding_112, Importance: 0.008403350599110126\n",
      "Feature: word_embedding_13, Importance: 0.008383005857467651\n",
      "Feature: word_embedding_114, Importance: 0.00831668172031641\n",
      "Feature: word_embedding_230, Importance: 0.008241815492510796\n",
      "Feature: word_embedding_286, Importance: 0.007648213300853968\n",
      "Feature: word_embedding_274, Importance: 0.007561400532722473\n",
      "Feature: word_embedding_74, Importance: 0.007492722477763891\n",
      "Feature: word_embedding_142, Importance: 0.0072141485288739204\n",
      "Feature: word_embedding_284, Importance: 0.007166839204728603\n",
      "Feature: word_embedding_92, Importance: 0.007004693616181612\n",
      "Feature: word_embedding_94, Importance: 0.00697499280795455\n",
      "Feature: word_embedding_28, Importance: 0.006660090293735266\n",
      "Feature: word_embedding_146, Importance: 0.006646445021033287\n",
      "Feature: word_embedding_42, Importance: 0.0065492140129208565\n",
      "Feature: word_embedding_107, Importance: 0.006465157959610224\n",
      "Feature: word_embedding_133, Importance: 0.006376061122864485\n",
      "Feature: word_embedding_5, Importance: 0.0063666109926998615\n",
      "Feature: word_embedding_145, Importance: 0.006274147890508175\n",
      "Feature: word_embedding_179, Importance: 0.006221773102879524\n",
      "Feature: word_embedding_235, Importance: 0.006219315342605114\n",
      "Feature: word_embedding_255, Importance: 0.00620908010751009\n",
      "Feature: word_embedding_55, Importance: 0.006180016323924065\n",
      "Feature: word_embedding_236, Importance: 0.005970012862235308\n",
      "Feature: word_embedding_156, Importance: 0.005944461096078157\n",
      "Feature: word_embedding_137, Importance: 0.005817974451929331\n",
      "Feature: word_embedding_22, Importance: 0.005786036141216755\n",
      "Feature: word_embedding_172, Importance: 0.0057780384086072445\n",
      "Feature: word_embedding_25, Importance: 0.005715401843190193\n",
      "Feature: word_embedding_59, Importance: 0.005581604782491922\n",
      "Feature: word_embedding_105, Importance: 0.005487182177603245\n",
      "Feature: word_embedding_240, Importance: 0.005433038808405399\n",
      "Feature: word_embedding_218, Importance: 0.005376750603318214\n",
      "Feature: word_embedding_23, Importance: 0.005337115377187729\n",
      "Feature: word_embedding_121, Importance: 0.005151731427758932\n",
      "Feature: word_embedding_69, Importance: 0.005145629867911339\n",
      "Feature: word_embedding_76, Importance: 0.005071708466857672\n",
      "Feature: word_embedding_31, Importance: 0.005060987547039986\n",
      "Feature: word_embedding_163, Importance: 0.005021120887249708\n",
      "Feature: word_embedding_38, Importance: 0.005012134555727243\n",
      "Feature: word_embedding_98, Importance: 0.004981518257409334\n",
      "Feature: word_embedding_227, Importance: 0.0049483380280435085\n",
      "Feature: word_embedding_219, Importance: 0.004946523811668158\n",
      "Feature: word_embedding_35, Importance: 0.004752601962536573\n",
      "Feature: word_embedding_128, Importance: 0.0047224233858287334\n",
      "Feature: word_embedding_294, Importance: 0.0046917591243982315\n",
      "Feature: word_embedding_53, Importance: 0.0046163820661604404\n",
      "Feature: word_embedding_208, Importance: 0.004544290713965893\n",
      "Feature: word_embedding_120, Importance: 0.004537361674010754\n",
      "Feature: word_embedding_108, Importance: 0.004490336403250694\n",
      "Feature: word_embedding_269, Importance: 0.0044761947356164455\n",
      "Feature: word_embedding_54, Importance: 0.004430418834090233\n",
      "Feature: word_embedding_152, Importance: 0.004421223886311054\n",
      "Feature: word_embedding_100, Importance: 0.004405359737575054\n",
      "Feature: word_embedding_15, Importance: 0.004383316729217768\n",
      "Feature: word_embedding_0, Importance: 0.004380383994430304\n",
      "Feature: word_embedding_96, Importance: 0.004354721866548061\n",
      "Feature: word_embedding_50, Importance: 0.0043503111228346825\n",
      "Feature: word_embedding_39, Importance: 0.004320139531046152\n",
      "Feature: word_embedding_126, Importance: 0.004307150840759277\n",
      "Feature: word_embedding_91, Importance: 0.004297137260437012\n",
      "Feature: word_embedding_271, Importance: 0.004286093637347221\n",
      "Feature: word_embedding_250, Importance: 0.004263691604137421\n",
      "Feature: word_embedding_243, Importance: 0.004239661619067192\n",
      "Feature: word_embedding_32, Importance: 0.004208843223750591\n",
      "Feature: word_embedding_275, Importance: 0.00420001894235611\n",
      "Feature: word_embedding_295, Importance: 0.004153773188591003\n",
      "Feature: word_embedding_280, Importance: 0.00415359390899539\n",
      "Feature: word_embedding_267, Importance: 0.00414075143635273\n",
      "Feature: word_embedding_140, Importance: 0.004138726741075516\n",
      "Feature: word_embedding_194, Importance: 0.004119005519896746\n",
      "Feature: word_embedding_157, Importance: 0.00410512974485755\n",
      "Feature: word_embedding_183, Importance: 0.004030835814774036\n",
      "Feature: word_embedding_262, Importance: 0.003996502608060837\n",
      "Feature: word_embedding_190, Importance: 0.0039860256947577\n",
      "Feature: word_embedding_189, Importance: 0.00395973352715373\n",
      "Feature: word_embedding_290, Importance: 0.003951072692871094\n",
      "Feature: word_embedding_4, Importance: 0.003945250529795885\n",
      "Feature: word_embedding_165, Importance: 0.003866457613185048\n",
      "Feature: word_embedding_206, Importance: 0.003826176980510354\n",
      "Feature: word_embedding_215, Importance: 0.0037945504300296307\n",
      "Feature: word_embedding_111, Importance: 0.003756118705496192\n",
      "Feature: word_embedding_7, Importance: 0.0037351571954786777\n",
      "Feature: word_embedding_170, Importance: 0.003718080697581172\n",
      "Feature: word_embedding_277, Importance: 0.003701103152707219\n",
      "Feature: word_embedding_149, Importance: 0.003685608971863985\n",
      "Feature: word_embedding_123, Importance: 0.0035740917082875967\n",
      "Feature: word_embedding_178, Importance: 0.003541974350810051\n",
      "Feature: word_embedding_78, Importance: 0.0035159746184945107\n",
      "Feature: word_embedding_115, Importance: 0.0034563762601464987\n",
      "Feature: word_embedding_51, Importance: 0.003446761751547456\n",
      "Feature: word_embedding_21, Importance: 0.0034337977413088083\n",
      "Feature: word_embedding_298, Importance: 0.0034266433212906122\n",
      "Feature: word_embedding_192, Importance: 0.0034074445720762014\n",
      "Feature: word_embedding_266, Importance: 0.0033733544405549765\n",
      "Feature: word_embedding_180, Importance: 0.0033640798646956682\n",
      "Feature: word_embedding_211, Importance: 0.00332582276314497\n",
      "Feature: word_embedding_63, Importance: 0.003324012504890561\n",
      "Feature: word_embedding_241, Importance: 0.003297151532024145\n",
      "Feature: skin, Importance: 0.0032337659504264593\n",
      "Feature: word_embedding_141, Importance: 0.0031866212375462055\n",
      "Feature: word_embedding_83, Importance: 0.003146047005429864\n",
      "Feature: word_embedding_1, Importance: 0.003120969282463193\n",
      "Feature: word_embedding_130, Importance: 0.0030951497610658407\n",
      "Feature: word_embedding_56, Importance: 0.0030891599599272013\n",
      "Feature: word_embedding_104, Importance: 0.0030783270485699177\n",
      "Feature: word_embedding_68, Importance: 0.0030693227890878916\n",
      "Feature: word_embedding_161, Importance: 0.003023117780685425\n",
      "Feature: word_embedding_33, Importance: 0.003020112169906497\n",
      "Feature: word_embedding_268, Importance: 0.002984844148159027\n",
      "Feature: word_embedding_257, Importance: 0.00295386859215796\n",
      "Feature: word_embedding_10, Importance: 0.002905413741245866\n",
      "Feature: word_embedding_228, Importance: 0.0029040600638836622\n",
      "Feature: word_embedding_159, Importance: 0.0028907584492117167\n",
      "Feature: word_embedding_239, Importance: 0.002889958443120122\n",
      "Feature: word_embedding_232, Importance: 0.0028400144074112177\n",
      "Feature: word_embedding_18, Importance: 0.0028276152443140745\n",
      "Feature: word_embedding_160, Importance: 0.0027660306077450514\n",
      "Feature: word_embedding_197, Importance: 0.0027459654957056046\n",
      "Feature: word_embedding_8, Importance: 0.0027350899763405323\n",
      "Feature: word_embedding_14, Importance: 0.0027102830354124308\n",
      "Feature: word_embedding_87, Importance: 0.0027031286153942347\n",
      "Feature: word_embedding_41, Importance: 0.0026935532223433256\n",
      "Feature: word_embedding_221, Importance: 0.0026876814663410187\n",
      "Feature: word_embedding_167, Importance: 0.0026866765692830086\n",
      "Feature: word_embedding_47, Importance: 0.0026599732227623463\n",
      "Feature: word_embedding_73, Importance: 0.002649917034432292\n",
      "Feature: word_embedding_244, Importance: 0.002639009617269039\n",
      "Feature: word_embedding_65, Importance: 0.0026243410538882017\n",
      "Feature: word_embedding_276, Importance: 0.0025947755202651024\n",
      "Feature: word_embedding_20, Importance: 0.0025782748125493526\n",
      "Feature: word_embedding_139, Importance: 0.0025579447392374277\n",
      "Feature: word_embedding_70, Importance: 0.0025536108296364546\n",
      "Feature: word_embedding_67, Importance: 0.0025505267549306154\n",
      "Feature: word_embedding_143, Importance: 0.002537129446864128\n",
      "Feature: word_embedding_127, Importance: 0.002422917867079377\n",
      "Feature: word_embedding_231, Importance: 0.002355719916522503\n",
      "Feature: word_embedding_164, Importance: 0.0023247303906828165\n",
      "Feature: word_embedding_201, Importance: 0.002291550161316991\n",
      "Feature: word_embedding_187, Importance: 0.0022843284532427788\n",
      "Feature: word_embedding_45, Importance: 0.0022741344291716814\n",
      "Feature: word_embedding_186, Importance: 0.0022716731764376163\n",
      "Feature: word_embedding_58, Importance: 0.0022524860687553883\n",
      "Feature: word_embedding_224, Importance: 0.002227375516667962\n",
      "Feature: word_embedding_237, Importance: 0.002216772409155965\n",
      "Feature: word_embedding_150, Importance: 0.002199712907895446\n",
      "Feature: word_embedding_283, Importance: 0.0021993087138980627\n",
      "Feature: word_embedding_248, Importance: 0.0021948693320155144\n",
      "Feature: word_embedding_49, Importance: 0.0021793809719383717\n",
      "Feature: word_embedding_272, Importance: 0.002160301897674799\n",
      "Feature: word_embedding_125, Importance: 0.0021173590794205666\n",
      "Feature: word_embedding_37, Importance: 0.0021035184618085623\n",
      "Feature: word_embedding_253, Importance: 0.0020961191039532423\n",
      "Feature: word_embedding_265, Importance: 0.0020941852126270533\n",
      "Feature: word_embedding_118, Importance: 0.0020920787937939167\n",
      "Feature: word_embedding_93, Importance: 0.0020596457179635763\n",
      "Feature: word_embedding_155, Importance: 0.0020444258116185665\n",
      "Feature: word_embedding_89, Importance: 0.002014388795942068\n",
      "Feature: word_embedding_293, Importance: 0.001989080337807536\n",
      "Feature: word_embedding_162, Importance: 0.001986297545954585\n",
      "Feature: word_embedding_16, Importance: 0.001978423213586211\n",
      "Feature: word_embedding_34, Importance: 0.0019781338050961494\n",
      "Feature: word_embedding_238, Importance: 0.0019764937460422516\n",
      "Feature: word_embedding_64, Importance: 0.0019529539858922362\n",
      "Feature: word_embedding_256, Importance: 0.0019505691016092896\n",
      "Feature: word_embedding_214, Importance: 0.0019399685552343726\n",
      "Feature: word_embedding_225, Importance: 0.0019232352497056127\n",
      "Feature: word_embedding_168, Importance: 0.0019215925130993128\n",
      "Feature: word_embedding_85, Importance: 0.0018974567065015435\n",
      "Feature: word_embedding_97, Importance: 0.0018826142186298966\n",
      "Feature: word_embedding_285, Importance: 0.001868327846750617\n",
      "Feature: word_embedding_153, Importance: 0.0018523848848417401\n",
      "Feature: word_embedding_292, Importance: 0.0018523482140153646\n",
      "Feature: word_embedding_258, Importance: 0.001823557075113058\n",
      "Feature: word_embedding_296, Importance: 0.001797590753994882\n",
      "Feature: word_embedding_57, Importance: 0.0017894906923174858\n",
      "Feature: word_embedding_260, Importance: 0.0017856186022982001\n",
      "Feature: word_embedding_101, Importance: 0.0017316476441919804\n",
      "Feature: word_embedding_281, Importance: 0.0017125022131949663\n",
      "Feature: word_embedding_199, Importance: 0.0016989336581900716\n",
      "Feature: word_embedding_24, Importance: 0.0016922549111768603\n",
      "Feature: word_embedding_185, Importance: 0.0016733052907511592\n",
      "Feature: word_embedding_44, Importance: 0.0016611297614872456\n",
      "Feature: word_embedding_247, Importance: 0.0016546703409403563\n",
      "Feature: word_embedding_173, Importance: 0.0016178902005776763\n",
      "Feature: word_embedding_19, Importance: 0.0016013956628739834\n",
      "Feature: word_embedding_136, Importance: 0.001591266947798431\n",
      "Feature: word_embedding_151, Importance: 0.0015545181231573224\n",
      "Feature: word_embedding_102, Importance: 0.001532365451566875\n",
      "Feature: word_embedding_279, Importance: 0.0015220155473798513\n",
      "Feature: word_embedding_223, Importance: 0.0015152578707784414\n",
      "Feature: word_embedding_193, Importance: 0.0015071048401296139\n",
      "Feature: word_embedding_202, Importance: 0.0015052227536216378\n",
      "Feature: word_embedding_30, Importance: 0.0014851139858365059\n",
      "Feature: word_embedding_188, Importance: 0.0014817713527008891\n",
      "Feature: word_embedding_113, Importance: 0.001469228183850646\n",
      "Feature: word_embedding_3, Importance: 0.001445143367163837\n",
      "Feature: word_embedding_245, Importance: 0.001429692842066288\n",
      "Feature: word_embedding_234, Importance: 0.0014253284316509962\n",
      "Feature: word_embedding_242, Importance: 0.0014134730445221066\n",
      "Feature: word_embedding_144, Importance: 0.0014030798338353634\n",
      "Feature: word_embedding_148, Importance: 0.0013880537590011954\n",
      "Feature: word_embedding_210, Importance: 0.0013690994819626212\n",
      "Feature: word_embedding_222, Importance: 0.001367834280245006\n",
      "Feature: word_embedding_207, Importance: 0.0013280315324664116\n",
      "Feature: word_embedding_205, Importance: 0.0013247851748019457\n",
      "Feature: word_embedding_200, Importance: 0.001302095246501267\n",
      "Feature: word_embedding_166, Importance: 0.0012970323441550136\n",
      "Feature: word_embedding_119, Importance: 0.0012859600828960538\n",
      "Feature: word_embedding_195, Importance: 0.0012465303298085928\n",
      "Feature: word_embedding_110, Importance: 0.001237994758412242\n",
      "Feature: word_embedding_233, Importance: 0.0012037556152790785\n",
      "Feature: word_embedding_212, Importance: 0.00120184023398906\n",
      "Feature: word_embedding_134, Importance: 0.0011504774447530508\n",
      "Feature: word_embedding_46, Importance: 0.0011467422591522336\n",
      "Feature: word_embedding_72, Importance: 0.0011236247373744845\n",
      "Feature: word_embedding_29, Importance: 0.0011180295841768384\n",
      "Feature: word_embedding_288, Importance: 0.0010930878343060613\n",
      "Feature: word_embedding_117, Importance: 0.0010907987598329782\n",
      "Feature: word_embedding_17, Importance: 0.0010871028061956167\n",
      "Feature: word_embedding_289, Importance: 0.0010580471716821194\n",
      "Feature: word_embedding_299, Importance: 0.0010571960592642426\n",
      "Feature: word_embedding_75, Importance: 0.0010565280681475997\n",
      "Feature: word_embedding_135, Importance: 0.0010307347401976585\n",
      "Feature: word_embedding_116, Importance: 0.0010165654821321368\n",
      "Feature: word_embedding_147, Importance: 0.0009924917249009013\n",
      "Feature: word_embedding_175, Importance: 0.0009563330677337945\n",
      "Feature: word_embedding_77, Importance: 0.0009442964801564813\n",
      "Feature: word_embedding_138, Importance: 0.0009364424040541053\n",
      "Feature: word_embedding_90, Importance: 0.0009261378436349332\n",
      "Feature: word_embedding_270, Importance: 0.0009237416670657694\n",
      "Feature: word_embedding_6, Importance: 0.0008799500647000968\n",
      "Feature: word_embedding_249, Importance: 0.0008721028571017087\n",
      "Feature: word_embedding_273, Importance: 0.000867254042532295\n",
      "Feature: word_embedding_158, Importance: 0.0008571580983698368\n",
      "Feature: word_embedding_9, Importance: 0.0008557502296753228\n",
      "Feature: word_embedding_81, Importance: 0.0008519408293068409\n",
      "Feature: word_embedding_278, Importance: 0.0008502529235556722\n",
      "Feature: word_embedding_213, Importance: 0.0008294691797345877\n",
      "Feature: word_embedding_259, Importance: 0.0008289150428026915\n",
      "Feature: word_embedding_154, Importance: 0.0008031076868064702\n",
      "Feature: word_embedding_106, Importance: 0.0007892207358963788\n",
      "Feature: word_embedding_95, Importance: 0.0007855966687202454\n",
      "Feature: word_embedding_80, Importance: 0.000764412572607398\n",
      "Feature: word_embedding_43, Importance: 0.0007270428468473256\n",
      "Feature: word_embedding_103, Importance: 0.0007173226331360638\n",
      "Feature: word_embedding_61, Importance: 0.000708440609741956\n",
      "Feature: word_embedding_12, Importance: 0.000707005790900439\n",
      "Feature: word_embedding_86, Importance: 0.0006932246615178883\n",
      "Feature: word_embedding_129, Importance: 0.0006896296399645507\n",
      "Feature: word_embedding_182, Importance: 0.0006599861662834883\n",
      "Feature: word_embedding_252, Importance: 0.0006486111669801176\n",
      "Feature: word_embedding_220, Importance: 0.0006367918686009943\n",
      "Feature: word_embedding_11, Importance: 0.0006273954641073942\n",
      "Feature: word_embedding_122, Importance: 0.0005474315257743001\n",
      "Feature: word_embedding_282, Importance: 0.0005443925620056689\n",
      "Feature: word_embedding_2, Importance: 0.0005007050931453705\n",
      "Feature: word_embedding_88, Importance: 0.0004899271298199892\n",
      "Feature: word_embedding_109, Importance: 0.00047527780407108366\n",
      "Feature: word_embedding_263, Importance: 0.00046090807882137597\n",
      "Feature: word_embedding_254, Importance: 0.0004587708681356162\n",
      "Feature: word_embedding_79, Importance: 0.0004522760573308915\n",
      "Feature: word_embedding_264, Importance: 0.0004332757380325347\n",
      "Feature: word_embedding_26, Importance: 0.00042667490197345614\n",
      "Feature: word_embedding_62, Importance: 0.00042078187107108533\n",
      "Feature: word_embedding_131, Importance: 0.0004093288735020906\n",
      "Feature: word_embedding_184, Importance: 0.000406825914978981\n",
      "Feature: word_embedding_177, Importance: 0.0003823113802354783\n",
      "Feature: word_embedding_203, Importance: 0.00037579459603875875\n",
      "Feature: word_embedding_181, Importance: 0.00023318336752709\n",
      "Feature: word_embedding_229, Importance: 0.00023049101582728326\n",
      "Feature: word_embedding_297, Importance: 0.00021093613759148866\n",
      "Feature: word_embedding_169, Importance: 0.0001339089503744617\n",
      "Feature: word_embedding_132, Importance: 0.00011737619206542149\n",
      "Feature: word_embedding_27, Importance: 9.834825323196128e-05\n",
      "Feature: word_embedding_209, Importance: 9.376132948091254e-05\n",
      "Feature: word_embedding_171, Importance: 7.840417674742639e-05\n",
      "Feature: word_embedding_36, Importance: 5.059512113803066e-05\n",
      "Feature: word_embedding_40, Importance: 0.0\n",
      "Feature: word_embedding_71, Importance: 0.0\n",
      "Feature: word_embedding_84, Importance: 0.0\n",
      "Feature: word_embedding_217, Importance: 0.0\n",
      "Feature: word_embedding_246, Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Your existing code for data preparation...\n",
    "\n",
    "# Train an XGBoost model\n",
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, Y_train)\n",
    "xgboost_pred = xgboost_model.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(Y_test, xgboost_pred))\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = xgboost_model.feature_importances_\n",
    "\n",
    "# Combine word embedding feature names with 'skin' and 'face'\n",
    "word_embedding_feature_names = ['word_embedding_' + str(i) for i in range(X_embeddings.shape[1])]\n",
    "other_feature_names = ['skin', 'face']\n",
    "feature_names = word_embedding_feature_names + other_feature_names\n",
    "\n",
    "# Pair feature names with their importances\n",
    "features = dict(zip(feature_names, feature_importances))\n",
    "sorted_features = sorted(features.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Displaying feature importances\n",
    "for feature, importance in sorted_features:\n",
    "    print(f\"Feature: {feature}, Importance: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c14835-7b2f-49ee-bf68-df6fc66a5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import other data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
